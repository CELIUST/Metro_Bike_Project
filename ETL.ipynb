{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN3RtWMfJ6yEe8fBLnNlVeW"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"c_eZTOntzKhr"},"outputs":[],"source":["!pip install pyodbc"]},{"cell_type":"code","source":["import pandas as pd\n","import pyodbc\n","from io import StringIO\n","from pprint import pprint\n","from azure.storage.blob import BlobServiceClient, BlobClient, ContainerClient"],"metadata":{"id":"YeG8uy75zMx_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Azure Storage Account information\n","account_name = 'Censored'\n","account_key = 'Censored'\n","container_name = 'cis4400metrobikedata'\n","\n","# Create a BlobServiceClient\n","blob_service_client = BlobServiceClient(account_url=f\"https://{account_name}.blob.core.windows.net\", credential=account_key)\n","\n","# Get a reference to the container\n","container_client = blob_service_client.get_container_client(container_name)\n","\n","# ETL process\n","for blob in container_client.list_blobs():\n","    blob_client = container_client.get_blob_client(blob.name)\n","\n","    # Download the CSV content from Azure Storage\n","    blob_data = blob_client.download_blob()\n","    csv_content = blob_data.readall().decode('utf-8')\n","\n","    # Transform: Perform any data transformations using pandas\n","    # In this example, we convert the CSV content to a pandas DataFrame\n","    df = pd.read_csv(StringIO(csv_content))\n","\n","    # Load: Perform any data loading or further processing here\n","    print(\"Transformed DataFrame:\")\n","    pprint(df)"],"metadata":{"id":"se2KHUXGzPFV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.head()"],"metadata":{"id":"PplhBEYRzYVn"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.shape"],"metadata":{"id":"k4JerYbrzc1u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dtypes"],"metadata":{"id":"7mddYhIDze5H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# checking for duplicate rows\n","\n","duplicate_rows = df[df.duplicated()]\n","\n","# Print duplicate rows, if any\n","if not duplicate_rows.empty:\n","    print(\"Duplicate Rows Found:\")\n","    print(duplicate_rows)\n","else:\n","    print(\"No Duplicate Rows Found.\")"],"metadata":{"id":"CdyNIfr_zhAP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Checking for null values\n","\n","nan_counts = df.isna().sum()\n","\n","# Print NaN counts for each column\n","print(\"NaN Counts for Each Column:\")\n","print(nan_counts)"],"metadata":{"id":"Mb2Co5z4zj52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df['start_lat'].fillna(0, inplace=True)\n","df['start_lon'].fillna(0, inplace=True)\n","df['end_lat'].fillna(0, inplace=True)\n","df['end_lon'].fillna(0, inplace=True)"],"metadata":{"id":"lEPwIpJZzmIj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Re-checking for null values\n","\n","nan_counts = df.isna().sum()\n","\n","# Print NaN counts for each column\n","print(\"NaN Counts for Each Column:\")\n","print(nan_counts)"],"metadata":{"id":"5Ved4IW6zpHw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# List of columns to be converted\n","int64_columns = df.select_dtypes(include='int64').columns\n","\n","# Convert int64 columns to int32\n","df[int64_columns] = df[int64_columns].astype('int32')"],"metadata":{"id":"P_W7J8-Pzrrz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# List of columns to be converted\n","float64_columns = df.select_dtypes(include='float64').columns\n","\n","# Convert int64 columns to int32\n","df[float64_columns] = df[float64_columns].astype('float32')"],"metadata":{"id":"edbJDWVAzuc-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dtypes"],"metadata":{"id":"-TCWnSuDzxLq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Convert all columns to lowercase\n","df.columns = map(str.lower, df.columns)\n","df = df.applymap(lambda x: x.lower() if isinstance(x, str) else x)"],"metadata":{"id":"c215_rI8zzL6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Ensure the date columns are in datetime format\n","date_columns = ['start_time', 'end_time']\n","df[date_columns] = df[date_columns].apply(pd.to_datetime, format='%m/%d/%Y %H:%M', errors='coerce')\n","\n","# Extract year, month, day, hour, and minutes for 'start_time'\n","df['start_time_month'] = df['start_time'].dt.month\n","df['start_time_day'] = df['start_time'].dt.day\n","df['start_time_year'] = df['start_time'].dt.year\n","df['start_time_hour'] = df['start_time'].dt.hour\n","df['start_time_minutes'] = df['start_time'].dt.minute\n","\n","# Extract year, month, day, hour, and minutes for 'end_time'\n","df['end_time_month'] = df['end_time'].dt.month\n","df['end_time_day'] = df['end_time'].dt.day\n","df['end_time_year'] = df['end_time'].dt.year\n","df['end_time_hour'] = df['end_time'].dt.hour\n","df['end_time_minutes'] = df['end_time'].dt.minute"],"metadata":{"id":"iCOODklgz1zf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"id":"PAF1cZoRz4jF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generate unique station IDs based on trip IDs\n","df['station_id'] = df['trip_id'].astype(str) + '_' + df['start_station'].astype(str) + '_' + df['end_station'].astype(str)\n","\n","# Display DataFrame\n","print(df[['trip_id', 'station_id']])"],"metadata":{"id":"rwbjdTnIz61y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Sample check:\")\n","print(df[['trip_id', 'station_id']].sample(10))"],"metadata":{"id":"IFlslIyU0C6v"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generating integer ID based on unique values of 'trip_id', 'start_station', 'end_station', 'bike_id', 'start_time', and 'end_time'\n","df['time_id'] = pd.factorize(df[['trip_id', 'start_station', 'end_station', 'bike_id', 'start_time', 'end_time']].apply(tuple, axis=1))[0] + 1\n","\n","# Display the DataFrame\n","print(df[['trip_id', 'time_id']])"],"metadata":{"id":"2ee8M77F0F0N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(\"Sample check:\")\n","print(df[['trip_id', 'time_id']].sample(10))"],"metadata":{"id":"nN05v42_0MmF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dtypes"],"metadata":{"id":"lLB5K51P0PRx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# List of columns to be converted\n","int64_columns = [\n","    'trip_id',\n","    'duration',\n","    'start_station',\n","    'bike_id',\n","    'plan_duration',\n","    'start_time_month',\n","    'start_time_day',\n","    'start_time_year',\n","    'start_time_hour',\n","    'start_time_minutes',\n","    'end_station',\n","    'end_time_month',\n","    'end_time_day',\n","    'end_time_year',\n","    'end_time_hour',\n","    'end_time_minutes',\n","    'time_id'\n","]\n","\n","# Convert int64 columns to int32\n","df[int64_columns] = df[int64_columns].astype('int32')\n","\n","# Display the updated DataFrame\n","print(df.dtypes)"],"metadata":{"id":"KXcPUuVC0U08"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# List of columns to be converted to float32\n","float64_columns = [\n","    'start_lat',\n","    'start_lon',\n","    'end_lat',\n","    'end_lon'\n","]\n","\n","\n","\n","# Convert float64 columns to float32\n","df[float64_columns] = df[float64_columns].astype('float32')\n"],"metadata":{"id":"QPB85Ddr0Yqy"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df.dtypes"],"metadata":{"id":"MtxHkX5m0bha"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_clean = df"],"metadata":{"id":"uF8iJ8KA0eEj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_clean.dtypes"],"metadata":{"id":"-fAce9Cz0enC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Specify the path where you want to save the CSV file\n","save_directory = '/Users/tam/Downloads/Metro_bike_data_clean'\n","\n","# Create the directory if it does not exist\n","os.makedirs(save_directory, exist_ok=True)\n","\n","# Specify the full path including the filename\n","save_path = os.path.join(save_directory, 'Metro_bike_data_clean.csv')\n","\n","# Save the DataFrame to CSV\n","df_clean.to_csv(save_path, index=False)\n","\n","# Print a confirmation message\n","print(f\"DataFrame saved to: {save_path}\")"],"metadata":{"id":"z5dg0h2S0gsA"},"execution_count":null,"outputs":[]}]}